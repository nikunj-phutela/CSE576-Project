{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-11-26 10:21:14 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json: 392kB [00:00, 109MB/s]                     \n",
      "2024-11-26 10:21:15 INFO: Downloaded file to /Users/suyashsutar99/stanza_resources/resources.json\n",
      "2024-11-26 10:21:15 INFO: Loading these models for language: en (English):\n",
      "===============================\n",
      "| Processor | Package         |\n",
      "-------------------------------\n",
      "| tokenize  | combined        |\n",
      "| mwt       | combined        |\n",
      "| pos       | combined_charlm |\n",
      "===============================\n",
      "\n",
      "2024-11-26 10:21:15 INFO: Using device: cpu\n",
      "2024-11-26 10:21:15 INFO: Loading: tokenize\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/stanza/models/tokenization/trainer.py:82: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-11-26 10:21:16 INFO: Loading: mwt\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/stanza/models/mwt/trainer.py:201: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-11-26 10:21:16 INFO: Loading: pos\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/stanza/models/pos/trainer.py:139: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/stanza/models/common/pretrain.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(self.filename, lambda storage, loc: storage)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/stanza/models/common/char_model.py:271: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-11-26 10:21:16 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import stanza\n",
    "from fuzzywuzzy import fuzz\n",
    "import llm_api\n",
    "\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos')\n",
    "\n",
    "def mask_non_nouns(doc):\n",
    "    \"\"\"\n",
    "    Mask all words except nouns, then randomly mask 10% of the nouns.\n",
    "    Takes a spacy-like document as input.\n",
    "    Returns masked sentence and list of unmasked nouns.\n",
    "    \n",
    "    Args:\n",
    "        doc: A processed document where each token has .text, .xpos attributes\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (masked_sentence, list_of_unmasked_nouns)\n",
    "    \"\"\"\n",
    "    masked_words = []\n",
    "    noun_list = []\n",
    "    noun_positions = []\n",
    "    # First pass: mask non-nouns and collect nouns\n",
    "    for sentence in doc.sentences:\n",
    "        for i, word in enumerate(sentence.words): \n",
    "            if word.xpos.startswith('NN') or word.upos.startswith('ADJ') or word.upos.startswith('VERB'):\n",
    "                masked_words.append(word.text)\n",
    "                noun_list.append(word.text)\n",
    "                noun_positions.append(i)\n",
    "            else:\n",
    "                masked_words.append('()')\n",
    "    \n",
    "    # Calculate how many nouns to mask (10%)\n",
    "    num_nouns_to_mask = max(0, int(len(noun_list) * 0.1))\n",
    "    \n",
    "    # Randomly select noun positions to mask\n",
    "    if noun_positions:\n",
    "        positions_to_mask = random.sample(range(len(noun_positions)), num_nouns_to_mask)\n",
    "        \n",
    "        # Mask the selected nouns\n",
    "        for pos_idx in positions_to_mask:\n",
    "            actual_pos = noun_positions[pos_idx]\n",
    "            masked_words[actual_pos] = '()'\n",
    "            noun_list.pop(pos_idx)\n",
    "    \n",
    "    return ' '.join(masked_words), noun_list\n",
    "\n",
    "\n",
    "def check_similar_q(row, llm_id):\n",
    "    \"\"\"\n",
    "    Function to check if similar question has been by model\n",
    "\n",
    "    Args:\n",
    "        row: data to be processed, model: the model name\n",
    "\n",
    "    Returns:\n",
    "        Bool: matched \n",
    "    \"\"\"\n",
    "    similarity_threshold = 80\n",
    "    if 'Question' in row:\n",
    "        sentence = 'Question'\n",
    "    else: sentence = 'question'\n",
    "\n",
    "    doc = nlp(sentence)\n",
    "    print(doc)\n",
    "    mask_token = \"()\"\n",
    "    masked_sentence, noun_list = mask_non_nouns(doc)\n",
    "    mask_count = masked_sentence.count(mask_token)\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    completions = []\n",
    "\n",
    "    system_prompt = \"\"\n",
    "    user_prompt = \"\"\n",
    "\n",
    "    if llm_id in (2, 3):\n",
    "        system_prompt = (\n",
    "        \"You are a helpful assistant that completes masked words in questions. \"\n",
    "        f\"Provide natural and contextually appropriate completions. \"\n",
    "        f\"Replace the {mask_count} masked word(s) marked with {mask_token} with suitable terms. Provide just the question\")\n",
    "        user_prompt = f\"Complete this question by replacing the masked sections:\\n{masked_sentence}\"\n",
    "\n",
    "        for i in range(5):\n",
    "            response = llm_api.use_llm(llm_id, system_prompt, user_prompt, temp=1, top_k=5)\n",
    "            completions.append(response)\n",
    "\n",
    "    else:\n",
    "        system_prompt = \"You are a helpful assistant that completes masked words in questions.\" \n",
    "        f\"Provide natural and contextually appropriate question.\"\n",
    "        user_prompt = f\"\"\"\n",
    "        Complete the following question by replacing {mask_count} masked word(s) marked with {mask_token}.\n",
    "        Question: {masked_sentence}\n",
    "        \"\"\"\n",
    "        response = llm_api.use_llm(llm_id, system_prompt, user_prompt, temp=1, top_k=5)\n",
    "\n",
    "        completions = [\n",
    "            choice.message.content\n",
    "            for choice in response.choices\n",
    "        ]\n",
    "    \n",
    "    # Compare each completion with the original question\n",
    "    for completion in completions:\n",
    "        score = fuzz.ratio(sentence, completion)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_match = completion\n",
    "\n",
    "    matched = best_score >= similarity_threshold\n",
    "    if matched:\n",
    "        accurate_count += 1\n",
    "\n",
    "    return matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
