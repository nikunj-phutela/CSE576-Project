{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "\n",
    "# Create the Claude API client (you'll need to replace with your actual API key)\n",
    "client = anthropic.Anthropic(api_key=\"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\")\n",
    "\n",
    "def complete_masked_question(masked_question: str, model_name: str, mask_token: str = \"()\", num_completions: int = 5) -> list:\n",
    "    \"\"\"\n",
    "    Complete a masked question using Anthropic's Claude API to generate likely completions.\n",
    "    \n",
    "    Args:\n",
    "        masked_question (str): Question with masked words (e.g., \"What is the () of this ()?\")\n",
    "        mask_token (str): Token used to indicate masked words\n",
    "        num_completions (int): Number of different completions to generate\n",
    "    \n",
    "    Returns:\n",
    "        list: List of completed questions\n",
    "    \"\"\"\n",
    "    # Validate inputs\n",
    "    if not masked_question or mask_token not in masked_question:\n",
    "        return []\n",
    "    \n",
    "    # Count number of masks to help with prompt engineering\n",
    "    mask_count = masked_question.count(mask_token)\n",
    "    \n",
    "    # Create a system prompt that guides the completion\n",
    "    system_prompt = (\n",
    "        \"You are a helpful assistant that completes masked words in questions. \"\n",
    "        \"Provide natural and contextually appropriate completions. \"\n",
    "        f\"Replace the {mask_count} masked word(s) marked with {mask_token} with suitable terms. Provide just the question\"\n",
    "    )\n",
    "    \n",
    "    # Prepare the user prompt\n",
    "    user_prompt = f\"Complete this question by replacing the masked sections:\\n{masked_question}\"\n",
    "    \n",
    "    try:   \n",
    "        # Store completions\n",
    "        completions = []\n",
    "        \n",
    "        # Generate multiple completions\n",
    "        for _ in range(num_completions):\n",
    "            response = client.messages.create(\n",
    "                model= model_name,  \n",
    "                max_tokens=400,\n",
    "                system=system_prompt,\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                temperature=0.7 \n",
    "            )\n",
    "            \n",
    "            # Extract and store the completion\n",
    "            completions.append(response.content[0].text.strip())\n",
    "        \n",
    "        return completions\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating completions: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz \n",
    "\n",
    "\n",
    "def calculate_accuracy(data_path: str, model_name: str, similarity_threshold: int = 80):\n",
    "    # Load the data\n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    # Initialize counters and new DataFrame list\n",
    "    total_questions = len(df)\n",
    "    accurate_count = 0\n",
    "    results = []\n",
    "    \n",
    "    # Process each record\n",
    "    for index, row in df.iterrows():\n",
    "        if index >= 100: break\n",
    "        original_question = row['original_question']\n",
    "        masked_question = row['masked_question']\n",
    "        \n",
    "        # Get completions for the masked question\n",
    "        completions = complete_masked_question(masked_question, model_name)\n",
    "        \n",
    "        # Initialize variables for the best match\n",
    "        best_match = None\n",
    "        best_score = 0\n",
    "        \n",
    "        # Compare each completion with the original question\n",
    "        for completion in completions:\n",
    "            score = fuzz.ratio(original_question, completion)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_match = completion\n",
    "        \n",
    "        # Determine if the match meets the threshold\n",
    "        matched = best_score >= similarity_threshold\n",
    "        if matched:\n",
    "            accurate_count += 1\n",
    "        \n",
    "        # Append the record to the results\n",
    "        results.append({\n",
    "            'original_question': original_question,\n",
    "            'masked_question': masked_question,\n",
    "            'generated_question': best_match,\n",
    "            'matched': matched,\n",
    "            'similarity_score': best_score\n",
    "        })\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy_percentage = (accurate_count / 100) * 100\n",
    "    print(f\"Accuracy: {accuracy_percentage}%\")\n",
    "    \n",
    "    # Create a new DataFrame from results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Return the results DataFrame\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating completions: Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}\n",
      "Error generating completions: Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}\n",
      "Accuracy: 41.0%\n",
      "\n",
      "Data saved to 'accuracy_claude3-5sonnet.csv'\n"
     ]
    }
   ],
   "source": [
    "data_path = \"Data/masked_mmlu.csv\"\n",
    "processed_df = calculate_accuracy(data_path, \"claude-3-5-sonnet-20241022\")\n",
    "\n",
    "processed_df.to_csv(\"Data/MMLU/accuracy_claude3-5sonnet.csv\", index=False)\n",
    "print(\"\\nData saved to 'accuracy_claude3-5sonnet.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 18.0%\n",
      "\n",
      "Data saved to 'accuracy_claude3sonnet.csv'\n"
     ]
    }
   ],
   "source": [
    "processed_df = calculate_accuracy(data_path, \"claude-3-sonnet-20240229\")\n",
    "\n",
    "processed_df.to_csv(\"Data/MMLU/accuracy_claude3sonnet.csv\", index=False)\n",
    "print(\"\\nData saved to 'accuracy_claude3sonnet.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "\n",
    "# Create the Claude API client (you'll need to replace with your actual API key)\n",
    "client = anthropic.Anthropic(api_key=\"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\")\n",
    "\n",
    "def complete_masked_question(masked_question: str, model_name: str, mask_token: str = \"()\", num_completions: int = 5) -> list:\n",
    "    \"\"\"\n",
    "    Complete a masked question using Anthropic's Claude API to generate likely completions.\n",
    "    \n",
    "    Args:\n",
    "        masked_question (str): Question with masked words (e.g., \"What is the () of this ()?\")\n",
    "        mask_token (str): Token used to indicate masked words\n",
    "        num_completions (int): Number of different completions to generate\n",
    "    \n",
    "    Returns:\n",
    "        list: List of completed questions\n",
    "    \"\"\"\n",
    "    # Validate inputs\n",
    "    if not masked_question or mask_token not in masked_question:\n",
    "        return []\n",
    "    \n",
    "    # Count number of masks to help with prompt engineering\n",
    "    mask_count = masked_question.count(mask_token)\n",
    "    \n",
    "    # Create a system prompt that guides the completion\n",
    "    system_prompt = (\n",
    "        \"You are a helpful assistant that completes masked words in questions. \"\n",
    "        \"Provide natural and contextually appropriate completions. \"\n",
    "        f\"Replace the {mask_count} masked word(s) marked with {mask_token} with suitable terms. Provide just the question\"\n",
    "    )\n",
    "    \n",
    "    # Prepare the user prompt\n",
    "    user_prompt = f\"Complete this question by replacing the masked sections:\\n{masked_question}\"\n",
    "    \n",
    "    try:   \n",
    "        # Store completions\n",
    "        completions = []\n",
    "        \n",
    "        # Generate multiple completions\n",
    "        for _ in range(num_completions):\n",
    "            response = client.messages.create(\n",
    "                model= model_name,  \n",
    "                max_tokens=400,\n",
    "                system=system_prompt,\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                temperature=1, \n",
    "                # top_k= num_completions \n",
    "            )\n",
    "        # print(response)\n",
    "            # Extract and store the completion\n",
    "            completions.append(response.content[0].text.strip())\n",
    "        \n",
    "        return completions\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating completions: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['How do you spit out watermelon seeds?', 'How many small black crunchy watermelon seeds are in a watermelon?', 'How many watermelon seeds are there in a watermelon?', 'How many can you fit in your mouth with watermelon seeds?', 'What do you call the black dried out pieces inside a watermelon?']\n"
     ]
    }
   ],
   "source": [
    "masked_question = \"() () () () () () () watermelon seeds ()?\"\n",
    "\n",
    "completions = complete_masked_question(masked_question, \"claude-3-sonnet-20240229\")\n",
    "\n",
    "print(completions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
