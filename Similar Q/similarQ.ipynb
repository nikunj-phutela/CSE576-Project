{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "def complete_masked_question(masked_question: str, mask_token: str = \"()\", num_completions: int = 5) -> list:\n",
    "    \"\"\"\n",
    "    Complete a masked question using OpenAI's API to generate likely completions.\n",
    "    \n",
    "    Args:\n",
    "        masked_question (str): Question with masked words (e.g., \"What is the () of this ()?\")\n",
    "        api_key (str): OpenAI API key\n",
    "        mask_token (str): Token used to indicate masked words\n",
    "        num_completions (int): Number of different completions to generate\n",
    "    Returns:\n",
    "        list: List of completed questions\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Count number of masks to help with prompt engineering\n",
    "    mask_count = masked_question.count(mask_token)\n",
    "    \n",
    "    # Create a prompt that encourages filling in the masks\n",
    "    system_prompt = \"You are a helpful assistant that completes masked words in questions. Provide natural and contextually appropriate question.\"\n",
    "    user_prompt = f\"\"\"\n",
    "    Complete the following question by replacing {mask_count} masked word(s) marked with {mask_token}.\n",
    "    Question: {masked_question}\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        n=num_completions\n",
    "    )\n",
    "\n",
    "    completions = [\n",
    "        choice.message.content\n",
    "        for choice in response.choices\n",
    "    ]\n",
    "    \n",
    "    return completions\n",
    "    \n",
    "# masked_question = \"() () () () () () () watermelon seeds ()?\"\n",
    "\n",
    "# completions = complete_masked_question(masked_question=masked_question)\n",
    "\n",
    "# print(completions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_question = \"() () () () () () () () meal () () swimming ()?\"\n",
    "\n",
    "completions = complete_masked_question(masked_question=masked_question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Question: Did you enjoy your delicious meal before going swimming?', 'Question: Have you ever enjoyed a delicious homemade meal before going swimming?', 'Question: Did you enjoy your delicious meal before going swimming?', 'Question: Did you enjoy your delicious meal before going swimming?', 'Question: Did you enjoy your delicious meal before going swimming?']\n"
     ]
    }
   ],
   "source": [
    "print(completions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz \n",
    "\n",
    "\n",
    "def calculate_accuracy(data_path: str, similarity_threshold: int = 80):\n",
    "    # Load the data\n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    # Initialize counters and new DataFrame list\n",
    "    total_questions = len(df)\n",
    "    accurate_count = 0\n",
    "    results = []\n",
    "    \n",
    "    # Process each record\n",
    "    for index, row in df.iterrows():\n",
    "        if index >= 100: break\n",
    "        original_question = row['original_question']\n",
    "        masked_question = row['masked_question']\n",
    "        \n",
    "        # Get completions for the masked question\n",
    "        completions = complete_masked_question(masked_question)\n",
    "        \n",
    "        # Initialize variables for the best match\n",
    "        best_match = None\n",
    "        best_score = 0\n",
    "        \n",
    "        # Compare each completion with the original question\n",
    "        for completion in completions:\n",
    "            score = fuzz.ratio(original_question, completion)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_match = completion\n",
    "        \n",
    "        # Determine if the match meets the threshold\n",
    "        matched = best_score >= similarity_threshold\n",
    "        if matched:\n",
    "            accurate_count += 1\n",
    "        \n",
    "        # Append the record to the results\n",
    "        results.append({\n",
    "            'original_question': original_question,\n",
    "            'masked_question': masked_question,\n",
    "            'generated_question': best_match,\n",
    "            'matched': matched,\n",
    "            'similarity_score': best_score\n",
    "        })\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy_percentage = (accurate_count / 100) * 100\n",
    "    print(f\"Accuracy: {accuracy_percentage}%\")\n",
    "    \n",
    "    # Create a new DataFrame from results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Return the results DataFrame\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 32.0%\n"
     ]
    }
   ],
   "source": [
    "data_path = \"Data/masked_mmlu.csv\"\n",
    "processed_df = calculate_accuracy(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data saved to 'accuracy.csv'\n"
     ]
    }
   ],
   "source": [
    "processed_df.to_csv(\"Data/MMLU/accuracy_gpt4o.csv\", index=False)\n",
    "print(\"\\nData saved to 'accuracy.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Claude 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "\n",
    "# Create the Claude API client (you'll need to replace with your actual API key)\n",
    "client = anthropic.Anthropic(api_key=\"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\")\n",
    "\n",
    "def complete_masked_question(masked_question: str, model_name: str, mask_token: str = \"()\", num_completions: int = 5) -> list:\n",
    "    \"\"\"\n",
    "    Complete a masked question using Anthropic's Claude API to generate likely completions.\n",
    "    \n",
    "    Args:\n",
    "        masked_question (str): Question with masked words (e.g., \"What is the () of this ()?\")\n",
    "        mask_token (str): Token used to indicate masked words\n",
    "        num_completions (int): Number of different completions to generate\n",
    "    \n",
    "    Returns:\n",
    "        list: List of completed questions\n",
    "    \"\"\"\n",
    "    # Validate inputs\n",
    "    if not masked_question or mask_token not in masked_question:\n",
    "        return []\n",
    "    \n",
    "    # Count number of masks to help with prompt engineering\n",
    "    mask_count = masked_question.count(mask_token)\n",
    "    \n",
    "    # Create a system prompt that guides the completion\n",
    "    system_prompt = (\n",
    "        \"You are a helpful assistant that completes masked words in questions. \"\n",
    "        \"Provide natural and contextually appropriate completions. \"\n",
    "        f\"Replace the {mask_count} masked word(s) marked with {mask_token} with suitable terms. Provide just the question\"\n",
    "    )\n",
    "    \n",
    "    # Prepare the user prompt\n",
    "    user_prompt = f\"Complete this question by replacing the masked sections:\\n{masked_question}\"\n",
    "    \n",
    "    try:   \n",
    "        # Store completions\n",
    "        completions = []\n",
    "        \n",
    "        # Generate multiple completions\n",
    "        for _ in range(num_completions):\n",
    "            response = client.messages.create(\n",
    "                model= model_name,  \n",
    "                max_tokens=400,\n",
    "                system=system_prompt,\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                temperature=0.7 \n",
    "            )\n",
    "            \n",
    "            # Extract and store the completion\n",
    "            completions.append(response.content[0].text.strip())\n",
    "        \n",
    "        return completions\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating completions: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz \n",
    "\n",
    "\n",
    "def calculate_accuracy(data_path: str, model_name: str, similarity_threshold: int = 80):\n",
    "    # Load the data\n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    # Initialize counters and new DataFrame list\n",
    "    total_questions = len(df)\n",
    "    accurate_count = 0\n",
    "    results = []\n",
    "    \n",
    "    # Process each record\n",
    "    for index, row in df.iterrows():\n",
    "        if index >= 100: break\n",
    "        original_question = row['original_question']\n",
    "        masked_question = row['masked_question']\n",
    "        \n",
    "        # Get completions for the masked question\n",
    "        completions = complete_masked_question(masked_question, model_name)\n",
    "        \n",
    "        # Initialize variables for the best match\n",
    "        best_match = None\n",
    "        best_score = 0\n",
    "        \n",
    "        # Compare each completion with the original question\n",
    "        for completion in completions:\n",
    "            score = fuzz.ratio(original_question, completion)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_match = completion\n",
    "        \n",
    "        # Determine if the match meets the threshold\n",
    "        matched = best_score >= similarity_threshold\n",
    "        if matched:\n",
    "            accurate_count += 1\n",
    "        \n",
    "        # Append the record to the results\n",
    "        results.append({\n",
    "            'original_question': original_question,\n",
    "            'masked_question': masked_question,\n",
    "            'generated_question': best_match,\n",
    "            'matched': matched,\n",
    "            'similarity_score': best_score\n",
    "        })\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy_percentage = (accurate_count / 100) * 100\n",
    "    print(f\"Accuracy: {accuracy_percentage}%\")\n",
    "    \n",
    "    # Create a new DataFrame from results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Return the results DataFrame\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 54.0%\n",
      "\n",
      "Data saved to 'accuracy_claude3-5sonnet.csv'\n"
     ]
    }
   ],
   "source": [
    "data_path = \"Data/masked_TruthfulQA.csv\"\n",
    "processed_df = calculate_accuracy(data_path, \"claude-3-5-sonnet-20241022\")\n",
    "\n",
    "processed_df.to_csv(\"Data/TruthfulQA/accuracy_claude3-5sonnet.csv\", index=False)\n",
    "print(\"\\nData saved to 'accuracy_claude3-5sonnet.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GSM8K - \n",
    "Claude 3 Sonnet - Accuracy: 9.0% \n",
    "Claude 3.5 Sonnet - Accuracy: 27.0%\n",
    "GPT 3.5 - Accuracy: 12.0%\n",
    "GPT 4o - Accuracy: 24.0%\n",
    "Llama 3.1 - Accuracy: \n",
    "\n",
    "\n",
    "\n",
    "TruthfulQA -\n",
    "Claude 3 Sonnet - Accuracy: 21.0%\n",
    "Claude 3.5 Sonnet - Accuracy: 54.0%\n",
    "GPT 3.5 - Accuracy: 51.0%\n",
    "GPT 4o - Accuracy: 64%\n",
    "Llama 3.1 - Accuracy: \n",
    "\n",
    "\n",
    "Commonsense - \n",
    "Claude 3 Sonnet - Accuracy: 10%\n",
    "Claude 3.5 Sonnet - Accuracy: 21.0%\n",
    "GPT 3.5 - Accuracy: 18.0%\n",
    "GPT 4o - Accuracy: 24.0%\n",
    "\n",
    "\n",
    "MMLU - \n",
    "Claude 3 Sonnet - Accuracy: \n",
    "Claude 3.5 Sonnet - Accuracy: \n",
    "GPT 3.5 - Accuracy: 24.0%\n",
    "GPT 4o - Accuracy: 32.0%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 21.0%\n",
      "\n",
      "Data saved to 'accuracy_claude3sonnet.csv'\n"
     ]
    }
   ],
   "source": [
    "processed_df = calculate_accuracy(data_path, \"claude-3-sonnet-20240229\")\n",
    "\n",
    "processed_df.to_csv(\"Data/TruthfulQA/accuracy_claude3sonnet.csv\", index=False)\n",
    "print(\"\\nData saved to 'accuracy_claude3sonnet.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "def complete_masked_question(masked_question: str, model_name: str = \"ank028/Llama-3.2-1B-Instruct-gsm8k\", \n",
    "                           mask_token: str = \"()\", num_completions: int = 5) -> list:\n",
    "    \"\"\"\n",
    "    Complete a masked question using Llama model to generate likely completions.\n",
    "    \n",
    "    Args:\n",
    "        masked_question (str): Question with masked words (e.g., \"What is the () of this ()?\")\n",
    "        model_name (str): Name of the Llama model to use\n",
    "        mask_token (str): Token used to indicate masked words\n",
    "        num_completions (int): Number of different completions to generate\n",
    "    \n",
    "    Returns:\n",
    "        list: List of completed questions\n",
    "    \"\"\"\n",
    "    # Validate inputs\n",
    "    if not masked_question or mask_token not in masked_question:\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        # Initialize the pipeline\n",
    "        generator = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=model_name,\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map=\"auto\"\n",
    "        )\n",
    "        \n",
    "        # Count number of masks\n",
    "        mask_count = masked_question.count(mask_token)\n",
    "        \n",
    "        # Create prompt\n",
    "        system_prompt = (\n",
    "            \"You are a helpful assistant that completes masked words in questions. \"\n",
    "            \"Provide natural and contextually appropriate completions. \"\n",
    "            f\"Replace the {mask_count} masked word(s) marked with {mask_token} with suitable terms. \"\n",
    "            \"Provide just the completed question without any additional text.\"\n",
    "        )\n",
    "        \n",
    "        # Combine system and user prompts in Llama chat format\n",
    "        prompt = f\"<s>[INST] <<SYS>>\\n{system_prompt}\\n<</SYS>>\\n\\n\"\n",
    "        prompt += f\"Complete this question by replacing the masked sections:\\n{masked_question}[/INST]\"\n",
    "        \n",
    "        # Generate completions\n",
    "        outputs = generator(\n",
    "            prompt,\n",
    "            num_return_sequences=num_completions,\n",
    "            max_new_tokens=100,\n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "            pad_token_id=generator.tokenizer.eos_token_id,\n",
    "            return_full_text=False  # Only return the newly generated text\n",
    "        )\n",
    "        \n",
    "        # Extract and clean completions\n",
    "        completions = []\n",
    "        for output in outputs:\n",
    "            # Clean up the generated text\n",
    "            completed_question = output['generated_text'].strip()\n",
    "            completions.append(completed_question)\n",
    "        \n",
    "        return completions\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating completions: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating completions: Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "masked_question = \"() () () () () () () watermelon seeds ()?\"\n",
    "\n",
    "completions = complete_masked_question(masked_question=masked_question)\n",
    "\n",
    "print(completions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
