{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Question: How many black watermelon seeds are there?', 'Question: How many black watermelon seeds are there?', 'Question: How many black watermelon seeds are there?', 'Question: How many grams of watermelon seeds are in a typical watermelon?', 'Question: How many black watermelon seeds are there?']\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "def complete_masked_question(masked_question: str, mask_token: str = \"()\", num_completions: int = 5) -> list:\n",
    "    \"\"\"\n",
    "    Complete a masked question using OpenAI's API to generate likely completions.\n",
    "    \n",
    "    Args:\n",
    "        masked_question (str): Question with masked words (e.g., \"What is the () of this ()?\")\n",
    "        api_key (str): OpenAI API key\n",
    "        mask_token (str): Token used to indicate masked words\n",
    "        num_completions (int): Number of different completions to generate\n",
    "    Returns:\n",
    "        list: List of completed questions\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Count number of masks to help with prompt engineering\n",
    "    mask_count = masked_question.count(mask_token)\n",
    "    \n",
    "    # Create a prompt that encourages filling in the masks\n",
    "    system_prompt = \"You are a helpful assistant that completes masked words in questions. Provide natural and contextually appropriate question.\"\n",
    "    user_prompt = f\"\"\"\n",
    "    Complete the following question by replacing {mask_count} masked word(s) marked with {mask_token}.\n",
    "    Question: {masked_question}\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        n=num_completions\n",
    "    )\n",
    "\n",
    "    completions = [\n",
    "        choice.message.content\n",
    "        for choice in response.choices\n",
    "    ]\n",
    "    \n",
    "    return completions\n",
    "    \n",
    "masked_question = \"() () () () () () () watermelon seeds ()?\"\n",
    "\n",
    "completions = complete_masked_question(masked_question=masked_question)\n",
    "\n",
    "print(completions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_question = \"() () () () () () () () meal () () swimming ()?\"\n",
    "\n",
    "completions = complete_masked_question(masked_question=masked_question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Question: Did you enjoy your delicious meal before going swimming?', 'Question: Have you ever enjoyed a delicious homemade meal before going swimming?', 'Question: Did you enjoy your delicious meal before going swimming?', 'Question: Did you enjoy your delicious meal before going swimming?', 'Question: Did you enjoy your delicious meal before going swimming?']\n"
     ]
    }
   ],
   "source": [
    "print(completions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz \n",
    "\n",
    "\n",
    "def calculate_accuracy(data_path: str, similarity_threshold: int = 80):\n",
    "    # Load the data\n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    # Initialize counters and new DataFrame list\n",
    "    total_questions = len(df)\n",
    "    accurate_count = 0\n",
    "    results = []\n",
    "    \n",
    "    # Process each record\n",
    "    for index, row in df.iterrows():\n",
    "        if index >= 100: break\n",
    "        original_question = row['original_question']\n",
    "        masked_question = row['masked_question']\n",
    "        \n",
    "        # Get completions for the masked question\n",
    "        completions = complete_masked_question(masked_question)\n",
    "        \n",
    "        # Initialize variables for the best match\n",
    "        best_match = None\n",
    "        best_score = 0\n",
    "        \n",
    "        # Compare each completion with the original question\n",
    "        for completion in completions:\n",
    "            score = fuzz.ratio(original_question, completion)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_match = completion\n",
    "        \n",
    "        # Determine if the match meets the threshold\n",
    "        matched = best_score >= similarity_threshold\n",
    "        if matched:\n",
    "            accurate_count += 1\n",
    "        \n",
    "        # Append the record to the results\n",
    "        results.append({\n",
    "            'original_question': original_question,\n",
    "            'masked_question': masked_question,\n",
    "            'generated_question': best_match,\n",
    "            'matched': matched,\n",
    "            'similarity_score': best_score\n",
    "        })\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy_percentage = (accurate_count / 100) * 100\n",
    "    print(f\"Accuracy: {accuracy_percentage}%\")\n",
    "    \n",
    "    # Create a new DataFrame from results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Return the results DataFrame\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 51.0%\n"
     ]
    }
   ],
   "source": [
    "data_path = \"Data/masked_TruthfulQA_2.csv\"\n",
    "processed_df = calculate_accuracy(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data saved to 'accuracy.csv'\n"
     ]
    }
   ],
   "source": [
    "processed_df.to_csv(\"Data/accuracy_2.csv\", index=False)\n",
    "print(\"\\nData saved to 'accuracy.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
